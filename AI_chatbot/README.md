# ğŸ› ï¸ Using ollama to run LLM model locally. Use langchain in python 
